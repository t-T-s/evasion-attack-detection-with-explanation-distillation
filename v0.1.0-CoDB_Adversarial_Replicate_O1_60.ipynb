{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T17:56:31.689248Z",
     "start_time": "2025-04-14T17:56:31.679681Z"
    }
   },
   "source": [
    "print('hello')\n",
    "import os\n",
    "from sys import executable as exec\n",
    "print('current working directory: ', os.getcwd())\n",
    "print('current conda environment: ', exec)\n",
    "\n",
    "#--notebook-dir=/home/spatial01/RND/adversarial-detector/adversarial-detector-xai"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "current working directory:  /home/spatial01/RND/adversarial-detector/adversarial-detector-xai\n",
      "current conda environment:  /home/spatial01/anaconda3/envs/netslab_lime_defense/bin/python\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T17:56:39.890142Z",
     "start_time": "2025-04-14T17:56:31.747683Z"
    }
   },
   "source": [
    "import DeepMIMO\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat, savemat \n",
    "import glob\n",
    "import re \n",
    "import datetime as dt\n",
    "\n",
    "# %% Machine Learning\n",
    "import keras\n",
    "import keras.models as models\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "# Adversarial attack libraries\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from myutils import evasion_attacks, create_dir_if_not_exist\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8] # Set default plot size"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 18:56:32.879755: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 18:56:32.884249: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-14 18:56:32.947037: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-14 18:56:32.947073: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-14 18:56:32.947111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 18:56:32.958052: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-14 18:56:32.959078: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-14 18:56:34.374460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:56:40.393994Z",
     "start_time": "2025-04-14T17:56:40.377370Z"
    }
   },
   "source": [
    "def beamforming_codebook(ant_shape = np.array([1, 32, 1]), oversampling_rate = np.array([1, 1, 1]), kd = 0.5):\n",
    "    \n",
    "    kd = 2 * np.pi * kd\n",
    "    codebook_size = ant_shape * oversampling_rate\n",
    "    \n",
    "    vecs = []\n",
    "    for dim in range(3):\n",
    "        ind = np.arange(ant_shape[dim]).reshape((-1, 1))\n",
    "        codebook_ang = np.linspace(0, np.pi, codebook_size[dim], endpoint = False).reshape((1, -1))                                                                                                     \n",
    "        vec = np.sqrt(1./ant_shape[dim]) * np.exp(-1j * kd * ind * np.cos(codebook_ang))\n",
    "        vecs.append(vec)\n",
    "        \n",
    "    F = np.kron(vecs[2], np.kron(vecs[1], vecs[0]))\n",
    "    \n",
    "    return F"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:56:40.521343Z",
     "start_time": "2025-04-14T17:56:40.500191Z"
    }
   },
   "source": [
    "\n",
    "##%% # Generate the dataset\n",
    "# # Load and print the default parameters\n",
    "parameters = DeepMIMO.default_params()\n",
    "\n",
    "\n",
    "# # Change parameters for the setup\n",
    "# Scenario O1_60 extracted at the dataset_folder\n",
    "parameters['scenario'] = 'O1_60'\n",
    "parameters['dataset_folder'] = os.path.abspath(\"assets/scenarios\") # Set DeepMIMO dataset folder that has O1_60\n",
    "\n",
    "parameters['num_paths'] = 5\n",
    "\n",
    "# User rows 1000 to 1300\n",
    "parameters['user_row_first'] = 1000\n",
    "parameters['user_row_last'] = 1300\n",
    "\n",
    "# Activate the BSs 3, 4, 5, 6\n",
    "parameters['active_BS'] = np.array([ 3, 4, 5, 6]) \n",
    "\n",
    "parameters['OFDM']['bandwidth'] = 0.5 # 50 MHz\n",
    "parameters['OFDM']['subcarriers'] = 1024 # OFDM with 512 subcarriers\n",
    "parameters['OFDM']['subcarriers_limit'] = 64 # Keep only first 64 subcarriers\n",
    "\n",
    "parameters['enable_BS2BS'] = False\n",
    "\n",
    "parameters['ue_antenna']['shape'] = np.array([1, 1, 1]) # Single antenna\n",
    "parameters['bs_antenna']['shape'] = np.array([1, 32, 8]) # UPA (2D matrix shaped antenna) of 256 elements (32 x 8)\n",
    "parameters['bs_antenna']['radiation_pattern'] = 'halfwave-dipole'\n",
    "parameters['ue_antenna']['radiation_pattern'] = 'halfwave-dipole'\n",
    "\n",
    "pprint(parameters, sort_dicts = False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': '/home/spatial01/RND/adversarial-detector/adversarial-detector-xai/assets/scenarios',\n",
      " 'scenario': 'O1_60',\n",
      " 'dynamic_settings': {'first_scene': 1, 'last_scene': 1},\n",
      " 'num_paths': 5,\n",
      " 'active_BS': array([3, 4, 5, 6]),\n",
      " 'user_row_first': 1000,\n",
      " 'user_row_last': 1300,\n",
      " 'row_subsampling': 1,\n",
      " 'user_subsampling': 1,\n",
      " 'bs_antenna': {'shape': array([ 1, 32,  8]),\n",
      "                'spacing': 0.5,\n",
      "                'radiation_pattern': 'halfwave-dipole'},\n",
      " 'ue_antenna': {'shape': array([1, 1, 1]),\n",
      "                'spacing': 0.5,\n",
      "                'radiation_pattern': 'halfwave-dipole'},\n",
      " 'enable_BS2BS': False,\n",
      " 'OFDM_channels': 1,\n",
      " 'OFDM': {'subcarriers': 1024,\n",
      "          'subcarriers_limit': 64,\n",
      "          'subcarriers_sampling': 1,\n",
      "          'bandwidth': 0.5,\n",
      "          'RX_filter': 0}}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-14T17:56:40.576392Z"
    }
   },
   "source": [
    "# %%script --false\n",
    "# Takes around 3 mins to generate the dataset\n",
    "dataset = DeepMIMO.generate_data(parameters)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 3\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 235300/235300 [00:08<00:00, 28759.87it/s]\n",
      "Generating channels: 100%|██████████| 54481/54481 [00:34<00:00, 1591.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 4\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 235300/235300 [00:08<00:00, 26922.66it/s]\n",
      "Generating channels: 100%|██████████| 54481/54481 [00:32<00:00, 1683.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 5\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing:  41%|████▏     | 97175/235300 [00:02<00:03, 38763.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# %%script --false\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Takes around 3 mins to generate the dataset\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mDeepMIMO\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/netslab_lime_defense/lib/python3.9/site-packages/DeepMIMO/generator.py:47\u001B[0m, in \u001B[0;36mgenerate_data\u001B[0;34m(params)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# If static scenario\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     42\u001B[0m     params[c\u001B[38;5;241m.\u001B[39mPARAMSET_SCENARIO_FIL] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     43\u001B[0m                                 os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(params[c\u001B[38;5;241m.\u001B[39mPARAMSET_DATASET_FOLDER]), \n\u001B[1;32m     44\u001B[0m                                 params[c\u001B[38;5;241m.\u001B[39mPARAMSET_SCENARIO], \n\u001B[1;32m     45\u001B[0m                                 params[c\u001B[38;5;241m.\u001B[39mPARAMSET_SCENARIO]\n\u001B[1;32m     46\u001B[0m                                 )\n\u001B[0;32m---> 47\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_scene_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dataset\n",
      "File \u001B[0;32m~/anaconda3/envs/netslab_lime_defense/lib/python3.9/site-packages/DeepMIMO/generator.py:60\u001B[0m, in \u001B[0;36mgenerate_scene_data\u001B[0;34m(params)\u001B[0m\n\u001B[1;32m     57\u001B[0m safe_print(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBasestation \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m bs_indx)\n\u001B[1;32m     59\u001B[0m safe_print(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mUE-BS Channels\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 60\u001B[0m dataset[i][c\u001B[38;5;241m.\u001B[39mDICT_UE_IDX], dataset[i][c\u001B[38;5;241m.\u001B[39mOUT_LOC] \u001B[38;5;241m=\u001B[39m \u001B[43mread_raytracing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbs_indx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m dataset[i][c\u001B[38;5;241m.\u001B[39mDICT_UE_IDX][c\u001B[38;5;241m.\u001B[39mOUT_CHANNEL] \u001B[38;5;241m=\u001B[39m generate_MIMO_channel(dataset[i][c\u001B[38;5;241m.\u001B[39mDICT_UE_IDX][c\u001B[38;5;241m.\u001B[39mOUT_PATH], \n\u001B[1;32m     62\u001B[0m                                                                                          params, \n\u001B[1;32m     63\u001B[0m                                                                                          params[c\u001B[38;5;241m.\u001B[39mPARAMSET_ANT_BS][i], \n\u001B[1;32m     64\u001B[0m                                                                                          params[c\u001B[38;5;241m.\u001B[39mPARAMSET_ANT_UE])\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m params[c\u001B[38;5;241m.\u001B[39mPARAMSET_BS2BS]:\n",
      "File \u001B[0;32m~/anaconda3/envs/netslab_lime_defense/lib/python3.9/site-packages/DeepMIMO/raytracing.py:29\u001B[0m, in \u001B[0;36mread_raytracing\u001B[0;34m(bs_id, params, user)\u001B[0m\n\u001B[1;32m     26\u001B[0m     generation_idx \u001B[38;5;241m=\u001B[39m params[c\u001B[38;5;241m.\u001B[39mPARAMSET_ACTIVE_BS]\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# Active BS IDX\u001B[39;00m\n\u001B[1;32m     28\u001B[0m ray_data \u001B[38;5;241m=\u001B[39m load_ray_data(scenario_files, bs_id, user\u001B[38;5;241m=\u001B[39muser)\n\u001B[0;32m---> 29\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mextract_data_from_ray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgeneration_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m bs_loc \u001B[38;5;241m=\u001B[39m load_bs_loc(scenario_files, bs_id)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data, bs_loc\n",
      "File \u001B[0;32m~/anaconda3/envs/netslab_lime_defense/lib/python3.9/site-packages/DeepMIMO/raytracing.py:85\u001B[0m, in \u001B[0;36mextract_data_from_ray\u001B[0;34m(ray_data, ids, params)\u001B[0m\n\u001B[1;32m     82\u001B[0m         data[c\u001B[38;5;241m.\u001B[39mOUT_DIST][j] \u001B[38;5;241m=\u001B[39m ray_data[c\u001B[38;5;241m.\u001B[39mLOAD_FILE_EXT[\u001B[38;5;241m4\u001B[39m]][user, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     83\u001B[0m         j \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 85\u001B[0m     pointer \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mnum_paths_available\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\n\u001B[1;32m     87\u001B[0m path_verifier\u001B[38;5;241m.\u001B[39mnotify()\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# The reading operation of the raytracing is linear\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;66;03m# Therefore, it is re-ordered to return in the same order of user IDs\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:22:24.246079Z",
     "start_time": "2025-04-14T16:22:24.228080Z"
    }
   },
   "source": [
    "##%% Parameters and Codebook\n",
    "F = beamforming_codebook(ant_shape = parameters['bs_antenna'][0]['shape'], oversampling_rate = np.array([1, 2, 1]), kd = parameters['bs_antenna'][0]['spacing'])\n",
    "\n",
    "num_OFDM = int(parameters['OFDM']['subcarriers_limit']/parameters['OFDM']['subcarriers_sampling'])\n",
    "num_beams = F.shape[1]\n",
    "num_bs = len(parameters['active_BS'])\n",
    "num_ue = len(parameters['active_UE'])\n",
    "\n",
    "NF = 5             # Noise figure at the base station\n",
    "Process_Gain = 10  # Channel estimation processing gain\n",
    "BW = parameters['OFDM']['bandwidth'] * 1e9 # System bandwidth in Hz\n",
    "noise_power_dB = -204 + 10*np.log10(BW/parameters['OFDM']['subcarriers']) + NF - Process_Gain; # Noise power in dB\n",
    "noise_power = 10**(.1*(noise_power_dB)); # Noise power\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-14T16:22:24.259301Z"
    }
   },
   "source": [
    "##%% DL Input-Output\n",
    "input_norm = np.zeros((num_bs, num_ue, num_OFDM), dtype=complex)\n",
    "max_rates = np.zeros((num_bs, num_ue, num_beams))\n",
    "for bs_idx in tqdm(range(num_bs), desc='Neural Network Input-Output Generation-BS', position=0, leave=True):\n",
    "    for ue_idx in tqdm(range(num_ue), desc='Neural Network Input-Output Generation-BS-%i'%bs_idx, position=0, leave=True):\n",
    "        ch = dataset[bs_idx]['user']['channel'][ue_idx].squeeze()\n",
    "        ch = ch + np.sqrt(noise_power) * (np.random.randn(*(ch.shape)) + 1j * np.random.randn(*(ch.shape)))\n",
    "        input_norm[bs_idx, ue_idx, :] = ch[0, :]\n",
    "        max_rates[bs_idx, ue_idx, :] = np.sum(np.log2(1 + np.abs(ch.T.conj() @ F)**2),  axis = 0)/num_OFDM\n",
    "        \n",
    "# Input reshape - normalize\n",
    "input_norm = np.transpose(input_norm, axes=[1, 0, 2])\n",
    "input_norm = input_norm.reshape((num_ue, -1))\n",
    "input_norm /=  np.amax(np.abs(input_norm))\n",
    "\n",
    "# Output reshape - normalize\n",
    "max_rates_norm_factor = np.amax(max_rates, axis=2, keepdims=True)\n",
    "max_rates_norm_factor[max_rates_norm_factor== 0] = 1 # Do not normalize if all zeros\n",
    "max_rates /= max_rates_norm_factor\n",
    "max_rates = np.transpose(max_rates, axes=[1, 0, 2])\n",
    "max_rates = max_rates.reshape((num_ue, -1))\n",
    "\n",
    "# Save the dataset\n",
    "data_dir = create_dir_if_not_exist(os.path.join(os.getcwd(), \"data/DeepMIMO_data/\"))\n",
    "\n",
    "# create_dir_if_not_exist(os.path.join(data_dir, \"DLCB_dataset_\"+dt.datetime.now().strftime(\"%d-%m-%y\")))\n",
    "\n",
    "## if not os.path.exists(os.path.join(data_dir, \"DLCB_dataset_\"+dt.datetime.now().strftime(\"%d-%m-0%y\"))):\n",
    "##     os.makedirs(os.path.join(data_dir, \"DLCB_dataset_\"+dt.datetime.now().strftime(\"%d-%m-%y\")))\n",
    "\n",
    "new_dataset_dir = create_dir_if_not_exist(os.path.join(data_dir, \"DLCB_dataset_\"+dt.datetime.now().strftime(\"%d-%m-%y\")))\n",
    "\n",
    "savemat(os.path.join(new_dataset_dir, 'DLCB_input.mat'), {'DL_input': input_norm})\n",
    "savemat(os.path.join(new_dataset_dir,'DLCB_output.mat'), {'DL_output': max_rates})\n",
    "\n",
    "input_data_path = os.path.join(new_dataset_dir, 'DLCB_input.mat')\n",
    "output_data_path = os.path.join(new_dataset_dir,'DLCB_output.mat')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neural Network Input-Output Generation-BS-0: 100%|██████████| 54481/54481 [02:12<00:00, 410.74it/s]\n",
      "Neural Network Input-Output Generation-BS-1: 100%|██████████| 54481/54481 [02:21<00:00, 383.78it/s]\n",
      "Neural Network Input-Output Generation-BS-2:  89%|████████▉ | 48760/54481 [02:17<00:22, 250.79it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:13:31.298843200Z",
     "start_time": "2024-02-28T15:02:31.471028100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model training function\n",
    "def train(In_train, Out_train, In_test, Out_test,\n",
    "          epochs, batch_size,dr,\n",
    "          num_hidden_layers, nodes_per_layer,\n",
    "          loss_fn,n_BS,n_beams):\n",
    "    \n",
    "    in_shp = list(In_train.shape[1:])\n",
    "\n",
    "    AP_models = []\n",
    "    for bs_idx in range(n_BS):\n",
    "        idx_str = 'BS%i' % bs_idx\n",
    "        idx = bs_idx*n_beams\n",
    "        \n",
    "        model = models.Sequential()\n",
    "        model.add(Dense(nodes_per_layer, activation='relu', kernel_initializer='he_normal', input_shape=in_shp))\n",
    "        model.add(Dropout(dr))\n",
    "        for h in range(num_hidden_layers):\n",
    "            model.add(Dense(nodes_per_layer, activation='relu', kernel_initializer='he_normal'))\n",
    "            model.add(Dropout(dr))\n",
    "        \n",
    "        model.add(Dense(n_beams, activation='relu', kernel_initializer='he_normal',\n",
    "                  name=\"dense\" + idx_str + \"o\"))\n",
    "        model.compile(loss=loss_fn, optimizer='adam')\n",
    "        model.summary()\n",
    "    \n",
    "        model.fit(In_train,\n",
    "                    Out_train[:, idx:idx + n_beams],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(In_test, Out_test[:,idx:idx + n_beams]),\n",
    "                    callbacks = [\n",
    "                        #keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
    "                        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "                    ])\n",
    "        AP_models.append(model)\n",
    "        \n",
    "    return AP_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T17:13:31.307846200Z",
     "start_time": "2024-02-28T15:02:31.486743900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading input and output sets generated from MATLAB\n",
    "In_set_file=loadmat(input_data_path)\n",
    "Out_set_file=loadmat(output_data_path)\n",
    "\n",
    "In_set=In_set_file['DL_input']\n",
    "Out_set=Out_set_file['DL_output']\n",
    "\n",
    "# Parameter initialization\n",
    "num_user_tot=In_set.shape[0]\n",
    "n_DL_size=[0.001, .05, .1, .15, .2, .25, .3, .35, .4, .45, .5, .55, .6, .65, .7, .75, .8, .85, .9, .95, 1.0]\n",
    "num_tot_TX=4\n",
    "num_beams=512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# %%script --false\n",
    "# Define it in this cell because it changes when the inside the for loop\n",
    "count=0\n",
    "\n",
    "results_dir = create_dir_if_not_exist(os.path.join(os.getcwd(), \"results/DeepMIMO_data_\"+dt.datetime.now().strftime(\"%d-%m-%y\")+\"/\"))\n",
    "output_model_dir = create_dir_if_not_exist(os.path.join(results_dir, \"Models\"))\n",
    "adv_data_dir = create_dir_if_not_exist(os.path.join(results_dir, 'AdvData'))\n",
    "\n",
    "for DL_size_ratio in n_DL_size:\n",
    "    \n",
    "    print (DL_size_ratio)\n",
    "    count=count+1\n",
    "    DL_size=int(num_user_tot*DL_size_ratio)\n",
    "    \n",
    "    np.random.seed(2016)\n",
    "    n_examples = DL_size\n",
    "    num_train  = int(DL_size * 0.8)\n",
    "    num_test   = int(num_user_tot*.2)\n",
    "    \n",
    "    train_index = np.random.choice(range(0,num_user_tot), size=num_train, replace=False)\n",
    "    rem_index = set(range(0,num_user_tot))-set(train_index)\n",
    "    test_index= list(set(np.random.choice(list(rem_index), size=num_test, replace=False)))\n",
    "    \n",
    "    In_train = In_set[train_index]\n",
    "    In_test =  In_set[test_index] \n",
    "        \n",
    "    Out_train = Out_set[train_index]\n",
    "    Out_test = Out_set[test_index]\n",
    "    \n",
    "    \n",
    "    # Learning model parameters\n",
    "    epochs = 10     \n",
    "    batch_size = 100  \n",
    "    dr = 0.05                  # dropout rate  \n",
    "    num_hidden_layers=4\n",
    "    nodes_per_layer=In_train.shape[1]\n",
    "    loss_fn='binary_crossentropy'\n",
    "    \n",
    "    # Model training\n",
    "    AP_models = train(In_train, Out_train, In_test, Out_test,\n",
    "                                          epochs, batch_size,dr,\n",
    "                                          num_hidden_layers, nodes_per_layer,\n",
    "                                          loss_fn, num_tot_TX, num_beams)\n",
    "    \n",
    "    # Save the benign models\n",
    "    for n_BS, model in enumerate(AP_models):\n",
    "        create_dir_if_not_exist(os.path.join(output_model_dir, f\"{DL_size_ratio}\"))\n",
    "        model.save(os.path.join(output_model_dir, f\"{DL_size_ratio}/model_{n_BS}.SavedModel\"), save_format='tf')\n",
    "\n",
    "    # Model running/testing\n",
    "    DL_Result={}\n",
    "    for idx in range(0,num_tot_TX,1): \n",
    "        # adversarial data injection\n",
    "        art_model = KerasClassifier(model=AP_models[idx], use_logits=False)\n",
    "        attack_type = \"fgsm\"\n",
    "        verbose = 2\n",
    "        print(\"Generating {} attack data\".format(attack_type))\n",
    "        fgsm_wrapped_model, fgsm_data = evasion_attacks.generate_evasion_data(wrapped_model=art_model\n",
    "                                                                            , attack_type=attack_type\n",
    "                                                                            , X_test=In_set\n",
    "                                                                            , verbose=verbose\n",
    "                                                                            , eps=0.4\n",
    "                                                                            , confidence=0.9\n",
    "                                                                            , nb_parallel=64\n",
    "                                                                             )\n",
    "        fgsm_data_test = fgsm_data[test_index]\n",
    "                \n",
    "        # Save the adversarial data as .mat file\n",
    "        create_dir_if_not_exist(os.path.join(adv_data_dir, f\"{DL_size_ratio}\"))\n",
    "        print(f\"Saving adversarial data for {DL_size_ratio} and {idx}\")\n",
    "        savemat(os.path.join(adv_data_dir, f\"{DL_size_ratio}/adv_data_test_{idx}.mat\"), {'adv_data_test': fgsm_data_test})\n",
    "        savemat(os.path.join(adv_data_dir, f\"{DL_size_ratio}/adv_data_full_{idx}.mat\"), {'adv_data_full': fgsm_data})\n",
    "        \n",
    "        beams_predicted=AP_models[idx].predict( fgsm_data_test, batch_size=10, verbose=0)\n",
    "        DL_Result['TX'+str(idx+1)+'Pred_Beams']=beams_predicted\n",
    "        DL_Result['TX'+str(idx+1)+'Opt_Beams']=Out_test[:,idx*num_beams:(idx+1)*num_beams]\n",
    "\n",
    "    DL_Result['user_index']=test_index\n",
    "    \n",
    "    DLCB_code_output_dir = create_dir_if_not_exist(os.path.join(results_dir, 'DLCB_code_output'))\n",
    "    # if not os.path.exists(os.path.join(results_dir, 'DLCB_code_output')):\n",
    "    #                       os.makedirs(os.path.join(results_dir, 'DLCB_code_output'))\n",
    "    savemat(os.path.join(DLCB_code_output_dir, 'DL_Result_')+str(count)+'.mat', DL_Result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Read Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% Read Results\n",
    "file_list = sorted(glob.glob(os.path.join(results_dir, 'DLCB_code_output/DL_Result*')), key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "num_files = len(file_list)\n",
    "\n",
    "user_index = []\n",
    "pred_beams = []\n",
    "opt_beams = []\n",
    "for file in tqdm(file_list, desc='Reading DL results'):\n",
    "    matfile = loadmat(file)\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    for idx in range(num_bs):\n",
    "        l1.append(matfile['TX'+str(idx+1)+'Pred_Beams'])\n",
    "        l2.append(matfile['TX'+str(idx+1)+'Opt_Beams'])\n",
    "        \n",
    "    pred_beams.append(l1)\n",
    "    opt_beams.append(l2)\n",
    "    user_index.append(matfile['user_index'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "user_index[file_idx].flatten()"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T15:08:46.348018200Z",
     "start_time": "2024-02-28T15:08:46.348018200Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "Pn = -204 + 10*np.log10(BW) # Noise power in dB\n",
    "SNR = 10**(.1*(0-Pn))\n",
    "\n",
    "ach_rate_DL = np.zeros(num_files)\n",
    "ach_rate_opt = np.zeros(num_files)\n",
    "\n",
    "eff_rate = np.zeros(num_files)\n",
    "opt_rate = np.zeros(num_files)\n",
    "for file_idx in tqdm(np.arange(num_files), desc = 'Calculating results'):\n",
    "    user_index_file = user_index[file_idx].flatten()\n",
    "    for ue_idx in range(len(user_index_file)):\n",
    "        eff_ch = []\n",
    "        opt_ch = []\n",
    "        for bs_idx in range(num_bs):\n",
    "            if file_idx == 0: # Random BF - 0 Samples\n",
    "                pred_beam_idx = np.random.randint(num_beams)\n",
    "            else:\n",
    "                pred_beam_idx = np.argmax(pred_beams[file_idx][bs_idx][ue_idx])\n",
    "            opt_beam_idx = np.argmax(opt_beams[file_idx][bs_idx][ue_idx])\n",
    "            ch_single_bs = dataset[bs_idx]['user']['channel'][user_index_file[ue_idx]].squeeze()\n",
    "            eff_ch_single_pred = ch_single_bs.T.conj() @ F[:, pred_beam_idx]\n",
    "            opt_ch_single_pred = ch_single_bs.T.conj() @ F[:, opt_beam_idx]\n",
    "            eff_ch.append(eff_ch_single_pred)\n",
    "            opt_ch.append(opt_ch_single_pred)\n",
    "        eff_ch = np.array(eff_ch)\n",
    "        opt_ch = np.array(opt_ch)\n",
    "        eff_rate[file_idx] += np.sum(np.log2(1 + SNR * np.abs(np.diag(eff_ch.conj().T @ eff_ch))))\n",
    "        opt_rate[file_idx] += np.sum(np.log2(1 + SNR * np.abs(np.diag(opt_ch.conj().T @ opt_ch))))\n",
    "    eff_rate[file_idx] /= len(user_index_file)*num_OFDM\n",
    "    opt_rate[file_idx] /= len(user_index_file)*num_OFDM\n",
    "\n",
    "\n",
    "# % Eff achievable rate calculations\n",
    "theta_user=(102/parameters['bs_antenna'][0]['shape'][1])*np.pi/180\n",
    "alpha=60*np.pi/180\n",
    "distance_user=10\n",
    "Tc_const=(distance_user*theta_user)/(2*np.sin(alpha)) # ms\n",
    "Tt=10*1e-6; # ms\n",
    "\n",
    "v_mph=50\n",
    "v=v_mph*1000*1.6/3600 # m/s\n",
    "Tc=Tc_const/v\n",
    "\n",
    "overhead_opt=1-(num_beams*Tt)/Tc # overhead of beam training\n",
    "overhead_DL=1-Tt/Tc # overhead of proposed DL method\n",
    "\n",
    "##%% Plotting the figure\n",
    "DL_size_array=np.arange(0, 2.5*num_files, 2.5);\n",
    "\n",
    "\n",
    "# if not os.path.exists(os.path.join(results_dir, 'Figs')):\n",
    "#     os.makedirs(os.path.join(results_dir, 'Figs'))\n",
    "\n",
    "results_figs_dir = create_dir_if_not_exist(os.path.join(results_dir, 'Figs'))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(DL_size_array, opt_rate, '--k', label = 'Genie-aided Coordinated Beamforming')\n",
    "plt.plot(DL_size_array, eff_rate*overhead_DL, '-bo', label = 'Deep Learning Coordinated Beamforming')\n",
    "plt.plot(DL_size_array, opt_rate*overhead_opt, '-rs', label = 'Baseline Coordinated Beamforming')\n",
    "plt.ylim([0, 6])\n",
    "plt.minorticks_on()\n",
    "plt.grid()\n",
    "plt.xlabel('Deep Learning Dataset Size (Thousand Samples)')\n",
    "plt.ylabel('Achievable Rate (bps/Hz)')\n",
    "plt.legend()\n",
    "current_time = dt.datetime.now().strftime(\"%d-%m-%y-%H%M%S\")\n",
    "plt.savefig(os.path.join(results_figs_dir, f'result{current_time}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T15:08:46.348018200Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"EOF - Code has finished executing !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lime_defense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
